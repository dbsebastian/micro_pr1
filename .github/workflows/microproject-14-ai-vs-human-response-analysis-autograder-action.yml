name: microproject-14-ai-vs-human-response-analysis Grading
'on':
  workflow_dispatch: {}
permissions:
  actions: write
  contents: read
  checks: read
jobs:
  autograding:
    name: autograding
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    - name: Checkout release repository
      uses: actions/checkout@v4
      with:
        repository: dsdiscovery/microprojects
        ref: microproject-14-ai-vs-human-response-analysis
        path: release
    - name: Checkout cell replacer
      uses: actions/checkout@v4
      with:
        repository: dsdiscovery/cell-replace
        path: cell-replace
    - name: Copy up-to-date grading files from release
      id: local-copy
      uses: illinois/local-copy@v2
      with:
        src_path: release/microproject-14-ai-vs-human-response-analysis
        dst_path: microproject-14-ai-vs-human-response-analysis
        copy: '.github/classroom : .github/classroom, requirements.txt : requirements.txt'
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        cache: pip
        cache-dependency-path: microproject-14-ai-vs-human-response-analysis/requirements.txt
    - run: pip install -r microproject-14-ai-vs-human-response-analysis/requirements.txt
    - name: Run cell-replace
      run: python cell-replace/cell-replace.py microproject-14-ai-vs-human-response-analysis/microproject-14-ai-vs-human-response-analysis.ipynb release/microproject-14-ai-vs-human-response-analysis/microproject-14-ai-vs-human-response-analysis.ipynb
    - name: Generate Test Script
      run: 'python3 -m jupyter2pytest microproject-14-ai-vs-human-response-analysis/microproject-14-ai-vs-human-response-analysis.ipynb "### TEST CASE for (.*)" microproject-14-ai-vs-human-response-analysis/test_microproject-14-ai-vs-human-response-analysis.py '
    - name: Generate Grading Artifacts
      run: cd microproject-14-ai-vs-human-response-analysis && python3 test_microproject-14-ai-vs-human-response-analysis.py && cd ..
    - name: Autograding
      id: autograding
      uses: illinois/autograding@v7
      with:
        path: microproject-14-ai-vs-human-response-analysis/
        test_suite: autograding
        step_summary: true
    - name: Record a Successful MicroProject (telemetry)
      uses: illinois/autograding-telemetry@v2
      continue-on-error: true
      with:
        endpoint: https://waf-server-01.cs.illinois.edu/autograder-telemetry/
        log_date: true
        assignment: microproject-14-ai-vs-human-response-analysis
        upstream_repo: dsdiscovery/microprojects
        autograding_status: ${{ steps.autograding.outcome }}
        points: ${{ steps.autograding.outputs.Points }}
